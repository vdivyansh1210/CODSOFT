# CODSOFT
Machine Learning Internship Tasks for CODSOFT
# CODSOFT Machine Learning Tasks

This repository contains solutions for three machine learning tasks as part of the **CODSOFT Internship Program**. Each task has been implemented in a structured way using Jupyter notebooks (`.ipynb`).

---

## ğŸ“‚ Repository Structure

```
CODSOFT/
â”‚
â”œâ”€â”€ Task-1/
â”‚   â””â”€â”€ Task_1.ipynb
â”‚
â”œâ”€â”€ Task-2/
â”‚   â””â”€â”€ Task2.ipynb
â”‚
â”œâ”€â”€ Task-3/
â”‚   â””â”€â”€ Task3.ipynb
â”‚
â””â”€â”€ README.md
```

---

## ğŸ“Š Tasks Overview

### **Task 1 â€“ Movie Genre Classification**

* **Objective**: Build a machine learning model that predicts the genre of a movie based on its plot summary or other textual information.
* **Techniques Used**: TF-IDF, Word Embeddings, Naive Bayes, Logistic Regression, SVM.
* **Dataset**: [IMDB Genre Classification Dataset](https://www.kaggle.com/datasets/hijest/genre-classification-dataset-imdb)

---

### **Task 2 â€“ Credit Card Fraud Detection**

* **Objective**: Build a model to detect fraudulent credit card transactions.
* **Techniques Used**: Logistic Regression, Decision Trees, Random Forests.
* **Dataset**: [Credit Card Fraud Detection Dataset](https://www.kaggle.com/datasets/kartik2112/fraud-detection)

---

### **Task 3 â€“ Customer Churn Prediction**

* **Objective**: Predict customer churn for a subscription-based service or business using historical data.
* **Techniques Used**: Logistic Regression, Random Forests, Gradient Boosting.
* **Dataset**: [Bank Customer Churn Prediction Dataset](https://www.kaggle.com/datasets/shantanudhakadd/bank-customer-churn-prediction)

---

## ğŸš€ How to Use

1. Clone this repository:

   ```bash
   git clone https://github.com/vdivyansh1210/CODSOFT.git
   cd CODSOFT
   ```

2. Navigate to the task folder you want to run:

   ```bash
   cd Task-1
   ```

3. Open the notebook in Jupyter or Google Colab:

   ```bash
   jupyter notebook task-1.ipynb
   ```

4. Download the dataset from the given Kaggle link and place it in the corresponding task folder before running the notebook.

---

## ğŸ“Œ Notes

* Datasets are **not uploaded** in this repository due to large file sizes. Please use the provided Kaggle links to download the datasets.
* Each notebook contains data preprocessing, model training, evaluation, and prediction steps.

---

âœï¸ **Author**: Divyansh Verma

