# CODSOFT
Machine Learning Internship Tasks for CODSOFT
# CODSOFT Machine Learning Tasks

This repository contains solutions for three machine learning tasks as part of the **CODSOFT Internship Program**. Each task has been implemented in a structured way using Jupyter notebooks (`.ipynb`).

---

## 📂 Repository Structure

```
CODSOFT/
│
├── Task-1/
│   └── Task_1.ipynb
│
├── Task-2/
│   └── Task2.ipynb
│
├── Task-3/
│   └── Task3.ipynb
│
└── README.md
```

---

## 📊 Tasks Overview

### **Task 1 – Movie Genre Classification**

* **Objective**: Build a machine learning model that predicts the genre of a movie based on its plot summary or other textual information.
* **Techniques Used**: TF-IDF, Word Embeddings, Naive Bayes, Logistic Regression, SVM.
* **Dataset**: [IMDB Genre Classification Dataset](https://www.kaggle.com/datasets/hijest/genre-classification-dataset-imdb)

---

### **Task 2 – Credit Card Fraud Detection**

* **Objective**: Build a model to detect fraudulent credit card transactions.
* **Techniques Used**: Logistic Regression, Decision Trees, Random Forests.
* **Dataset**: [Credit Card Fraud Detection Dataset](https://www.kaggle.com/datasets/kartik2112/fraud-detection)

---

### **Task 3 – Customer Churn Prediction**

* **Objective**: Predict customer churn for a subscription-based service or business using historical data.
* **Techniques Used**: Logistic Regression, Random Forests, Gradient Boosting.
* **Dataset**: [Bank Customer Churn Prediction Dataset](https://www.kaggle.com/datasets/shantanudhakadd/bank-customer-churn-prediction)

---

## 🚀 How to Use

1. Clone this repository:

   ```bash
   git clone https://github.com/vdivyansh1210/CODSOFT.git
   cd CODSOFT
   ```

2. Navigate to the task folder you want to run:

   ```bash
   cd Task-1
   ```

3. Open the notebook in Jupyter or Google Colab:

   ```bash
   jupyter notebook task-1.ipynb
   ```

4. Download the dataset from the given Kaggle link and place it in the corresponding task folder before running the notebook.

---

## 📌 Notes

* Datasets are **not uploaded** in this repository due to large file sizes. Please use the provided Kaggle links to download the datasets.
* Each notebook contains data preprocessing, model training, evaluation, and prediction steps.

---

✍️ **Author**: Divyansh Verma

